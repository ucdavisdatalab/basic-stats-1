# Inference

Inference means making statements about the population based on a sample. In one simple case, inference can mean using a sample to estimate the mean of the population from which it arose. Since the law of large numbers says that the sample mean tends to the population mean, we'll use the sample mean to approximate the population mean. You've already seen this in the plots where I showed the sample mean getting closer to the population mean as the sample size increased.

## Revisiting the standard normal distribution:
The distribution, density, and quantile functions are all about the population. When you're working with data, the graphs won't be as clean. When you're using methods that depend upon the data being approximately normal, you'll have to check some diagnostics. One simple but effective approach is to look at the histogram and QQ plot, and judge whether there is obvious non-normality. Here's an example from the standard normal distribution:

```{r}
# sample 50 numbers from the standard normal distribution
y = rnorm(50)

# look at the histogram - it's like the density function
hist(y)

# look at the QQ plot - it demonstrates how closely the distribution matches the quantiles of a Normal distribution.
qqnorm(y)

# plot a couple of non-normal QQ plots:
qqnorm( rexp(50) )
qqnorm( rt(50, df=2) )
```


## Looking at real data

### Normal data: using the t-distribution

In the `fosdata` package there is a dataset called `mice_pot`, which contains data from an experiment where mice were dosed with THC and then measured for motor activity as a percentage of their baseline activity. We are going to look at the group that got a medium dose of THC.

```{r}
# extract just the mice that got the medium dose of THC
mice_med = mice_pot[ mice_pot$group == 1, ]

# assess normality with histogram and QQ plot
hist( mice_med$percent_of_act )
qqnorm( mice_med$percent_of_act )
```

#### Find the 80% confidence interval for the population mean

Now we are using our sample to make some determination about the population, so this is statistical inference. Our best guess of the population mean is the sample mean, `mean( mice_med$percent_of_act )`, which is 99.1%. But to get a confidence interval, we need to use the formula
$$ \bar{x} \pm t_{n-1, 0.1} * S / \sqrt{n} $$
Going piece-by-piece in this formula:

```{r}
# calculate the sample mean, standard deviation, and sample size:
x_bar = mean( mice_med$percent_of_act )
s = sd( mice_med$percent_of_act )
n = nrow( mice_med )

# calculate the relevant quantiles of the t-distribution.
# use the 0.1 and 0.9 quantiles because we want the 80% CI
# and (1-0.8) / 2 = 0.1 and 1 - 0.1 = 0.9.
t_low = qt(0.1, df=n-1)
t_high = qt(0.9, df=n-1)

# calculate the confidence interval:
cat( "The 80% CI is (", x_bar + t_low * s / sqrt(n), ", ",
     x_bar + t_high * s / sqrt(n), ").")

# check your calculation with the t.test function:
t.test( mice_med$percent_of_act, conf.level=0.8 )

```

### Non-normal data: resampling

In the `fosdata` package, there is a dataset called `barnacles` that is from a study where scientists counted the number of barnacles on rocks in the intertidal zone. We'll import the data and look at its distribution:

```{r}
# calculate the number of barnacles per unit area for each sample:
barnacles$per_m = barnacles$count / barnacles$area_m

# examine the histogram and QQ plot of the barnacles per unit area:
hist( barnacles$per_m, main="barnacles per square meter" )
qqnorm( barnacles$per_m )

# does it look like the barnacles per unit area
# are distributed like a normal distribution?
```

We should conclude that the data are obviously non-normal.

#### Bootstrap-t distribution:
In this case, the observations themselves are not normally distributed so the t-distribution derived from the CLT will be only an approximation. But there is another option: resampling. This means shuffling our original data to generate new values of the t-statistic, and then working directly from this "bootstrap-t" distribution for inferences. Here is the procedure for generating your bootstrap-t distribution:

 1. Compute the sample mean $\bar{x}$.
 2. Repeat the following many times:
  - Resample from the barnacle data with replacement, calling the resample `z`.
  - Calculate the t-statistic (centered at $\bar{x}$) for this resample and call it `t_boot[[i]]`. The formula is `( mean(z) - mean(barnacles$per_m) ) / ( sd(z) / sqrt(n) )`.
 3. Get the quantiles from the bootstrap-t distribution.
 4. Calculate the confidence interval as 
 $$ (\bar{x} - t_{boot, lower} \times s / \sqrt{n}, \bar{x} + t_{boot, upper} \times s / \sqrt{n} $$

```{r}
# define the sample size and a vector to hold results
B = 1000
t_boot = numeric( B )

# generate the bootstrap-t distribution for this data
for (i in 1:B) {
  z = sample( barnacles$per_m, replace=TRUE )
  t_boot[[i]] = ( mean(z) - mean(barnacles$per_m) ) /
    ( sd(z) / sqrt(length(z)) )
}

# plot the histogram of the bootstrap-t distribution
hist(t_boot)

# annotate the histogram with 0.025 and 0.975 quantiles
t_lower = quantile( t_boot, 0.025 )
t_upper = quantile( t_boot, 0.975 )
abline( v = c(t_lower, t_upper), lty=3)

# calculate the confidence interval
round( mean(barnacles$per_m) + 
        c(t_lower, t_upper) * sd(barnacles$per_m) / 
        sqrt(length(barnacles$per_m)), 2 )

# compare to the result we'd see with a t confidence interval
t.test( barnacles$per_m )
```

## Hypothesis testing
We've seen how to generate some confidence intervals for locating the population mean based on a sample. Besides confidence intervals, another main topic of statistical inference is hypothesis testing.

### Null hypothesis and p-value
Recall that in statistical inference, we are using some sample to make conclusions about a population. The sample can't tell us what the population is, since many different populations could generate the same samples. But if we have a sample and a particular idea for a population, then we can see whether the sample is unlikely, given the proposed population.

When testing a hypothesis in statistics, you propose some specific hypothesis, called the null hypothesis. Then, you must evaluate how unusual the data are, given the assumption that the null hypothesis is true. As an example, let's test whether the mice that got a medium dose of THC have population mean activity that is equal to 100. Call this specific null mean $\mu_0$. Then the t-statistic for the test is

$$t = \frac{\bar{X} - \mu_0}{S / \sqrt{n} } = \frac{99.05 - 100}{S / \sqrt{12} } = -0.125$$

When working out the confidence interval, we already saw that these data are Normally distributed and the t-statistic for these data has 11 degrees of freedom. I will therefore draw the density of a t-distribution with 11 degrees of freedom, annotated with the observed t-statistic:

```{r one-pop-t}
# plot the t density with 11 df
xx = seq(-4, 4, length.out=1000)
plot( xx, dt(xx, df=11), type='l', bty='n', ylab="density", xlab='t')

# annotate with the observed t-statistic
t = (mean(mice_med$percent_of_act) - 100) /
  (sd(mice_med$percent_of_act) / sqrt(n))
abline(v=t, lty=3, col='red', lwd=2)
```


The observed t-statistic doesn't appear to be unusual under the assumed null, because it is from the fat part of the probability density. We can quantify that idea by shading the area under the density curve that is more rare than the observed t-statistic. The area of that shading is the probability that something equally or more unlikely than the observed data would occur if the null hypothesis is true. This gets called the p-value, and when it is small, we conclude that the null hypothesis should be rejected.

```{r one-pop-t-pval}
# plot the t density with 11 df
xx = seq(-4, 4, length.out=1000)
plot( xx, dt(xx, df=11), type='l', bty='n', ylab="density", xlab='t')

# annotate with the observed t-statistic
abline(v=t, lty=3, col='red', lwd=2)

# shade the tails
polygon(x=c(xx[xx<=t], t, min(xx)), y=c(dt(xx[xx<=t], df=11), 0, 0), col=grey(0.8))
polygon(x=c(xx[xx>-t], t, max(xx)), y=c(0, dt(xx[xx>-t], df=11), 0), col=grey(0.8))
```

Here, clearly, the shaded area is not small, so don't reject the null hypothesis. In the plot, I have shaded both the upper and lower tails. That's because the null hypothesis was not specific about whether the alternative is $\mu \ne 100$ or $\mu < 100$. If you wish, you may formulate a one-sided hypothesis (this needs to be done before looking at the data). As you may imagine, the shaded area is reduced if you take away one of the two tails and this makes it easier to reject a one-sided null hypothesis. The test can be done more simply with the t.test function:

```{r t.test-fun}
# test whether the population mean movement is equal to 100%
t.test( mice_med$percent_of_act, mu=100 )

# same test, but one-sided
t.test( mice_med$percent_of_act, mu=100, alternative='less')
```

### Two-population test
The test of $\mu_0 = 100$ is a one-population test because it seeks to compare a single population against a specified standard. On the other hand, you may wish to assess the null hypothesis that the movement of mice in the high-THC group is equal to the movement of mice in the medium-THC group. This is called a two-population test, since there are two populations to compare against each other. The null hypothesis is $\mu_{0, med} = \mu_{0, high}$. Testing a two-population hypothesis requires first assessing normality and also checking whether the variances are equal. There are separate procedures when the variances are equal vs. unequal.

```{r two-pop-t.test}
#extract the samples to be compared
a = mice_pot$percent_of_act[ mice_pot$group == 1]
b = mice_pot$percent_of_act[ mice_pot$group == 3]

# check for equal variances - these are close enough
var(a)
var(b)

# confirm equal variances with a boxplot
boxplot(a, b)

# check whether the high-THC mice movement is Normal
# (we already checked for the medium-dose mice)
qqnorm(b)

# two pop test
t.test(a, b, var.equal=TRUE)
```

As a side note, what counts as "equal" variance is a judgement call. I might say that variances within a factor of two are roughly equal. Here's an example of unequal variances, which is clearly discernable from the boxplot:

```{r cars-unequal-variances}
# import the mtcars data
data(mtcars)

# make a boxplot of mpg by cylinder count
boxplot( mpg ~ cyl, data=mtcars)
```

The variances of mpg for the si and eight cylinder cars are approximately equal to each other, but they are different from the variance of the mpg of four-cylinder cars.

### Hypothesis tests for non-normal data
Just as with the confidence intervals, there is a bootstrap hypothesis test that can be used where the data are not normal. There are other options, too, with clever derivations. The one I'll show you is the Wilcoxon test, which is based on the ranks of the data.

Since we'e already seen that the barnacles per square meter data are not normal, I will illustrate testing the null hypothesis that $\mu_0$ = 300 barnacles per square meter. This is a one-population test, and a two-sided alternative.

```{r wilcox-barnacles}
# wilcoxon test for 300 barnacles per square meter
wilcox.test( barnacles$per_m )
```

The same function can also be used for two-population testing, like the example of the medium vs. high THC doses:

```{r wilcoxon-thc}
# wilcoxon test of equality between high-THC and medium-THC mice
wilcox.test( a, b )
```


